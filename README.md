This project is an Exploratory Data Analysis (EDA) on the famous Pima Indians Diabetes dataset. It includes medical information for Pima women aged 21 and older, and its goal is to explore patterns associated with diabetes.

 link :https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database

Step 1 Summary , Real Dataset Information

ğŸ” Dataset Understanding & Initial Inspection (Real Values)

Rows & Columns:
768 rows, 9 columns

Columns:
Pregnancies, Glucose, BloodPressure, SkinThickness,
Insulin, BMI, DiabetesPedigreeFunction, Age, Outcome

Data Types:
All features are numeric.

Missing Values:
There are no formal NaNs, but there are biologically impossible zeros:

Glucose â†’ 5 zeros

BloodPressure â†’ 35 zeros

SkinThickness â†’ 227 zeros

Insulin â†’ 374 zeros

BMI â†’ 11 zeros

Real Descriptive Stats:

Mean Glucose â‰ˆ 120.9

Mean BMI â‰ˆ 31.99

Mean Age â‰ˆ 33.24

Max Pregnancies = 17

Target Distribution (actual):

0 â†’ 500 samples (65.1%)

1 â†’ 268 samples (34.9%)
â†’ The dataset is imbalanced.

Initial Observations:

Glucose, BMI, and Age appear to be the strongest early indicators.

Insulin contains many zeros and may need imputation.

Dataset requires cleaning before analysis.

Step 2 â€” Data Cleaning

ğŸ§¼ 1. Identifying Invalid Zero Values

Several features contained biologically impossible zeros:

Glucose â†’ 5 zeros

BloodPressure â†’ 35 zeros

SkinThickness â†’ 227 zeros

Insulin â†’ 374 zeros

BMI â†’ 11 zeros

These were treated as invalid values.

ğŸ”§ 2. Replacing Invalid Values

All invalid zeros were replaced using the median of each respective column.
Median was chosen to avoid distortion from outliers and preserve natural distribution.

After replacement:

No unrealistic zero values remained

Distributions became smoother and more reliable

ğŸ§¹ 3. Outlier Check

Outliers were reviewed but not aggressively removed, as EDA benefits from analyzing the natural variability of the data.

ğŸ” 4. Final Validation

After cleaning:

No missing or invalid values remained

Dataset became ready for visualization and deeper analysis

Step 3 â€” Statistical Analysis, Calculations & Feature Grouping

In this step, after data cleaning, detailed statistical analysis and feature grouping were performed to better understand the datasetâ€™s behavior.

ğŸ§® 1. Descriptive Statistics

For all features, the following metrics were calculated:

Mean

Median

Min / Max

Standard Deviation

Quartiles (Q1, Q3)

IQR

ğŸ”‘ Key Real Results:

Mean Glucose â‰ˆ 120.9

Mean BMI â‰ˆ 31.99

Mean Age â‰ˆ 33.24

Max Pregnancies = 17

These stats revealed which features have high variability (Glucose, BMI, Age) and which are more stable.

ğŸ“Š 2. Target Distribution

Actual class distribution:

0 â†’ 65.1% (Non-diabetic)

1 â†’ 34.9% (Diabetic)

Indicating that the dataset is imbalanced.

ğŸ—‚ 3. Feature Grouping (Binning)

Several numeric features were grouped for clearer insights.

â— Age Groups:

20â€“29 â†’ Young

30â€“39 â†’ Adult

40â€“49 â†’ Middle-aged

50+ â†’ Senior

â— BMI Categories:

< 18.5 â†’ Underweight

18.5â€“24.9 â†’ Normal

25â€“29.9 â†’ Overweight

â‰¥ 30 â†’ Obese

â— Pregnancies Groups:

0â€“2 â†’ Low

3â€“5 â†’ Medium

6+ â†’ High

Grouping made it easier to observe patterns in diabetes prevalence across age, BMI, and pregnancy counts.

ğŸ§  Summary of Step 3

Statistical metrics provided a clear picture of feature distributions.

Class imbalance was confirmed.

Step 4 , Data Visualization

In this step we visually explored the cleaned dataset using Matplotlib . The goal of visualization was to understand feature distributions, detect bivariate relationships, and extract actionable insights for further analysis and modeling.

Grouping helped reveal meaningful patterns such as higher diabetes rates in obese individuals and older age groups.

Each figure contains a short title, a description of plotted data, a few key insights, and suggestions for next steps. Visuals include histograms, boxplots, density plot , countplots for the target, scatterplots, line plot , bar plot , pie plot and a correlation heatmap.

Glucose , Density Plot (KDE)

<img width="824" height="534" alt="Screenshot 2025-11-29 230036" src="https://github.com/user-attachments/assets/abf781a0-d7e1-434e-a178-aadc770b683b" />

The Kernel Density Estimate (KDE) plot was used to examine the distribution of Glucose values in the Pima Indians dataset.

Key observations:

Mode: ~100â€“110, the most frequent glucose level in the dataset.

Skewness: Right-skewed; higher glucose values are less frequent but significant.

Range: Most observations are concentrated between 75â€“150.

Outliers: Very high glucose values (>200) exist but are rare.

Conclusion / Insight:

Glucose is a key feature for diabetes prediction.

Right skew indicates notable cases with high glucose levels.

For models sensitive to normality, log transformation or normalization may be considered for this feature.



